---
title: "MLOps 춘추 전국 시대 정리"
author: "Siheon Jo"
date: "2023-01-10"
categories: [Linux]
---
# MLOps
## 머신러닝 프로세스
1. 문제 정의
2. EDA
3. Feature 생성
4. 모델 학습
5. 예측
**위 프로세스는 자신의 컴퓨터, 서버 등에서 실행 고정된 데이터를 사용해 학습**
-> 이런 머신러닝 모델을 웹, 앱 서비스에 적용(Production 환경, Real World)

서버 : Docker 이미지로 인스턴스에 띄우기 또는 AWS Lambda(서버리스) 등을 활용

또는 API 형태로 만들지 않고 DB에 있는 데이터를 Batch 단위로 처리

1시간에 한번씩 예측해서 결과를 DB에 저장

Task Management 도구인 Airflow를 사용

## MLOps
MLOps = 머신러닝 엔지니어링 + 데이터 엔지니어링 + 인프로

ML + Ops

**머신러닝 모델 개발(ML)과 머신러닝 모델 운영(Ops)에서 사용되는 문제, 반복을 최소화하고 비지니스 가치를 창출하는 것이 목표**

모델링에 집중할 수 있도록 관련된 인프라를 만들고, 자동으로 운영되도록 만드는 일

예 : API 형태로 서버 만들기, 실험 파라미터와 결과 저장하기, 모델 결과 자동화하기, 데이터 Validation 등

**MLOps의 목표는 빠른 시간 내에 가장 적은 위험을 부담하며 아이디어 단계부터 프로덕션까지 ML 프로젝트를 진행할 수 있도록 기술적 마찰을 줄이는 것**

||Research ML|Production ML|
|---------|---------------|----------------|
|데이터|고정(Static)|계속 변함(Dynamic - Shifting)|
|중요 요소|모델 성능(Accuracy, RMSE 등)|모델 성능, 빠른 Inference 속도, 해석 가능함|
|도전 과제|더 좋은 성능을 내는 모델, 새로운 구조의 모델|안정적인 운영, 전체 시스템 구조|
|학습|데이터가 고정이라 모델구조, 파라미터 기반 재학습|시간의 흐름에 따라 데이터가 변경되어 재학습|
|목적|논문 출판|서비스에서 문제 해결|
|표현|Offline|Online|

## MLOps Component
### 집에서 요리하는 행위(Research)
음식 소스(Data / Feature) -> 요리하는 행위 (Train) -> 음식 (Model)
### 식당에서 요리하는 행위(Production)
음식 소스(Data / Feature) -> 요리하는 행위 (Train) -> 음식 (Model) -> 서빙(Batch Serving: 많은 양을 일정 주기로 한꺼번에 서빙(=음식 배달, 택배), Online Serving은 한번에 하나씩 포장해서 배송 동시에 여러 주문이 들어올 경우 확장 간으하도록 준비해야 함)

Serving: Production(Real World) 환경에 사용할 수 있도록 모델을 배포

대표적인 Serving 방식
1. Batch 단위로 여러 데이터를 한번에 예측하는 방법
    - (관련한 라이브러리는 거의 없음 익숙한 라이브러리로 작성하고 스케쥴링 실행)
    - Airflow, Cronjob 등으로 스케쥴링 작업
        - 학습 / 예측을 별도의 작업으로 설정
        - 학습: 1주일에 한번
        - 예측: 10분, 30분, 1시간에 1번씩
2. API 형태로 요청이 올 때마다 예측하는 방법
    Lv 1. Flask, Fast API
    Lv 2. Lv1 + Docker
    Lv 3. Lv2 + Kubernetes
    Lv 4. Serving 프레임워크 사용
        - 사용 프레임워크: Kubeflow, BentoML, Seldon Core, Cortex, KFServing, Tensorflow Serving, TorchServe 등

Serving 환경의 의존성: 라이브러리, 파이썬 버전 등

처음부터 API 형태로 Serving 하는것은 아니다.

서버와 실시간 통신을 꼭 해야하는 것이 아니라면, 최초에는 Batch Serving을 구축하는 것이 좋다.

Batch Serving의 결과를 DB에 저장하고, 서버는 그 데이터를 주기적으로 가져가는 방식으로 통신한다.

우선 머신러닝 모델을 운영하면서 점점 API 형태로 변환한다.

Serving 라이브러리는 점점 간단한 코드만 작성하면, Docker Image를 명령어 하나로 만들 수 있는 기능을 지원
    - BentoML

성능이 좋은것을 기록해놓는다.

이미지에 사용할 수도 있고 보관을 해둬서 모델 아티팩트 이미지파일 학습코드 학습모델 피클 파일을 의미

만들어진 프로덕트 환경에서 판매했던 판매하려고 만들어둔 모델에 대한 거는

언제 모델 생성일 그리고 모델 성능 등을 기록해놓는다

리서치 관점이랑 프로덕션이랑 익스피리먼트나 모델 관련 내용을 저장해두면 좋다.

머신러닝 모델 학습하는 과정을 ㅐㅁ번 기록한다.

여기선 아티팩트라는 단어가 많이 나오는데 학습하는 과정에서 생기는 이미지나 모델 파일을 의미한다.

단순히 기록하는 거는 파이썬 로그같은 것을 사용해서 되게 쉽게 할 수 있는데
중요한것은 기록을 편하게 볼 수 있는 모니터링 대시보드가 있으면 좋고 모든 실험을 기록하고 특정 메트릭 기준으로 제일 좋은것들을 선택하는 기준이 필요

이런것들은 weight & bias, nepune 오픈소스는 MLflow가 강세를 보인다

리서치관점의 모델 매니지먼트랑 프로덕션이랑 분리해서 운영을 하면 좋고

리서치에서 괜찮았떤 것들을 픽해서 프로덕션을 서빙으로 자동으로 보내주는 것들을 만들면 좋고

우버 논문에서 인상깊게 보았던것은 우버같은 경우 model selection rule example이라고 해서 모델을 선택하는 룰이 있다

메트릭의 mae가 5 이하일 때 모델을 선택해달라 이런 리스트를 가지고 온 다음에
어떤 모델을 선택할지 배포를 할지 이런걳ㅅ들을 연결할 수 있는 룰이 있어 특정 기준으로 모델을 선택할 수 있는 것들도 있으면 좋다.

github 스타 히스토리도 MLflow가 압도적으로 오픈소스 중에서 많은 인기를 누리고 있다.

요리별로 사용되는 재료들이 중복될 수 있다.

반죽이나 강 등을 미리 만들면 편하다고 할 수 있는데

이게 없이 타코 만든다고 하면 재료꺼내서 손질하고 하는 것이다

이런 재료를 가공해서 냉장고 같은 곳에 한꺼번에 저장을 해두는 것이다 미리미리 데이터를 가공하는건데 머신러닝 피쳐를 집계한 피쳐 스토어라고 부를 수 있다.

이제 요리별로 필요한 재료를 꺼내서 쓰기만 하면 되는것이고 요리 만들 때 재료를 처음부터 꺼내는 시간이 소요되지 않아 편리하고

프로덕션, 레스토랑과 리서치 맨처음에 재료가 다르다고 하였는데 이제 냉장고를 같이 운영을 해서 리서치랑 프롣거션에서 같은 재료를 사용해서 피쳐도 공통적으로 쓸 수 있도록 냉장고를 구축할 수 있다.

피쳐스토어라는 개념은 모델이 많아지면서 사용하는 피쳐가 중복되는 경우가 있는데 이런 경우에 한 번 집계해가지고 시간과 비용을 절약할 수 있다.

피쳐같은 경우도 재사용을 가능하게 만드는게 핵심이다.

최초에 batch 단위로 5분 단위로 쿼리를 실행하면서 DB테이블에 그 결과 값을 저장하고 그 테이블을 피쳐스토어로 사용하는 방법을 했다.

그 이후에는 실시간 데이터를 가지고 피쳐 스토어를 구성을 하였고 실시간 데이터를 사용해서 하려고 하면 레퍼런스가 생각보다 적다.

그래서 오픈소스 같은 경우는 거의 현존하는 건 두 세개 정도 밖에 없는데 아직 상용하기에는 애매한 상황이다.

대표적인 라이브러리는 feast나 hopsworkds가 대표적이다 